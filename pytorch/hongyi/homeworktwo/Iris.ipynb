{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-02T07:49:34.359503Z",
     "start_time": "2025-04-02T07:49:34.356173Z"
    }
   },
   "source": [
    "\n",
    "from sklearn import datasets\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ],
   "outputs": [],
   "execution_count": 101
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "fe2ea7a5ccfdf127"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:49:34.376106Z",
     "start_time": "2025-04-02T07:49:34.371038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 获取鸢尾花数据\n",
    "iris_datas = datasets.load_iris(return_X_y=True)\n",
    "target = iris_datas[1]\n",
    "iris_datas=torch.tensor(iris_datas[0]).float()\n",
    "\n",
    "print(target)\n"
   ],
   "id": "7b596fa26e31f431",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "execution_count": 102
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 自定义数据集",
   "id": "63402957ad3091cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:49:34.382769Z",
     "start_time": "2025-04-02T07:49:34.379110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class IrisDataset(Dataset):\n",
    "    def __init__(self, data,mode, target = None):\n",
    "        if mode == \"test\":\n",
    "            self.data = data\n",
    "        else:\n",
    "            if mode == \"train\":\n",
    "                idx = [i for i in range(len(data)) if i % 5 !=0 ]\n",
    "            elif mode == \"dev\":\n",
    "                idx = [i for i in range(len(data)) if i % 5 ==0 ]\n",
    "            self.data = data[idx]\n",
    "\n",
    "            self.target = target[idx]\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ],
   "id": "c6412ef0fe402f10",
   "outputs": [],
   "execution_count": 103
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 数据加载器\n",
   "id": "aba2b865c48067fd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:49:34.393100Z",
     "start_time": "2025-04-02T07:49:34.391094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def pre_datalpader(dataset,batch_size):\n",
    "    return DataLoader(dataset=dataset,batch_size=batch_size,shuffle=True)"
   ],
   "id": "91e1292a4b7aa145",
   "outputs": [],
   "execution_count": 104
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 定义神经网络\n",
   "id": "2e8f839301f13a5b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:49:34.404314Z",
     "start_time": "2025-04-02T07:49:34.400535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class IrisClassifier(nn.Module):\n",
    "    def __init__(self,input_dim, n_classes):\n",
    "        super(IrisClassifier, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, n_classes)\n",
    "        )\n",
    "        self.criterion = nn.MSELoss(reduction='mean')\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze()\n",
    "    def cal_loss(self, pred, target):\n",
    "        # 使用二叉熵损失函数\n",
    "        loss = self.criterion(pred, target)\n",
    "        return loss\n"
   ],
   "id": "575030c0e91beaba",
   "outputs": [],
   "execution_count": 105
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 训练神经网络",
   "id": "20a5a68cc6b5ebd1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:49:34.415841Z",
     "start_time": "2025-04-02T07:49:34.412696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(model,dataset,config,target):\n",
    "    n_epochs = config['n_epochs']\n",
    "    batch_size = config['batch_size']\n",
    "    learning_rate = config['learning_rate']\n",
    "    epochs = 0\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    tr_load = pre_datalpader(dataset,batch_size)\n",
    "    while epochs < n_epochs:\n",
    "        # 训练模式\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for x,y,*_ in tr_load:\n",
    "            optimizer.zero_grad()\n",
    "            x,y = x.to(config['device']), y.to(config['device'])\n",
    "            pred = model(x)\n",
    "            mse_loss = model.cal_loss(pred, y)\n",
    "            mse_loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += mse_loss.item() * x.size(0)\n",
    "        epoch_loss = running_loss / len(tr_load.dataset)\n",
    "        epochs += 1\n",
    "        print('epoch: {}, loss: {:.4f}'.format(epochs, epoch_loss))\n",
    "\n"
   ],
   "id": "4151492c36d221c0",
   "outputs": [],
   "execution_count": 106
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:49:34.427368Z",
     "start_time": "2025-04-02T07:49:34.423660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test(model,dataset,config):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    batch_size = config['batch_size']\n",
    "    td_load = pre_datalpader(dataset,batch_size)\n",
    "    with torch.no_grad():\n",
    "        total = 0.0\n",
    "        for x,y,*_ in td_load:\n",
    "            x,y = x.to(config['device']), y.to(config['device'])\n",
    "            pred = model(x)\n",
    "            print(type(pred))\n",
    "            loss = model.cal_loss(pred, y)\n",
    "            running_loss += loss.item() * x.size(0)\n",
    "            # _ ,pred = torch.max(pred, 1)\n",
    "            total +=   y.size(0)\n",
    "            correct = correct + (pred == y).sum().item()\n",
    "    epoch_loss = running_loss / len(dataset)\n",
    "    accuracy = 100.0 * correct / total\n",
    "    print(f'test_loss:{epoch_loss}, accuracy: {correct}')\n",
    "    return accuracy"
   ],
   "id": "dec0531a9e8e1989",
   "outputs": [],
   "execution_count": 107
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:49:36.793752Z",
     "start_time": "2025-04-02T07:49:34.435326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config = {\n",
    "    \"n_epochs\" : 300,\n",
    "    \"batch_size\" : 8,\n",
    "    \"learning_rate\" : 0.001,\n",
    "    'mode' : 'train',\n",
    "    'input_dim' : 4,\n",
    "    'n_classes' : 4,\n",
    "    'device':'cpu'\n",
    "}\n",
    "model = IrisClassifier(config['input_dim'],config['n_classes'])\n",
    "tr_dataset = IrisDataset(iris_datas,config['mode'],target)\n",
    "train(model,tr_dataset,config,target)\n",
    "\n"
   ],
   "id": "f56b2ed307ba9112",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 8.2972\n",
      "epoch: 2, loss: 5.6818\n",
      "epoch: 3, loss: 3.2337\n",
      "epoch: 4, loss: 1.9923\n",
      "epoch: 5, loss: 1.0501\n",
      "epoch: 6, loss: 0.8396\n",
      "epoch: 7, loss: 0.6527\n",
      "epoch: 8, loss: 0.9514\n",
      "epoch: 9, loss: 0.7483\n",
      "epoch: 10, loss: 0.8599\n",
      "epoch: 11, loss: 0.6104\n",
      "epoch: 12, loss: 0.5847\n",
      "epoch: 13, loss: 0.6632\n",
      "epoch: 14, loss: 0.6008\n",
      "epoch: 15, loss: 0.5832\n",
      "epoch: 16, loss: 0.7241\n",
      "epoch: 17, loss: 0.5767\n",
      "epoch: 18, loss: 0.6844\n",
      "epoch: 19, loss: 0.7427\n",
      "epoch: 20, loss: 0.5067\n",
      "epoch: 21, loss: 0.4456\n",
      "epoch: 22, loss: 0.7030\n",
      "epoch: 23, loss: 1.0036\n",
      "epoch: 24, loss: 0.5940\n",
      "epoch: 25, loss: 0.8752\n",
      "epoch: 26, loss: 0.5509\n",
      "epoch: 27, loss: 0.7783\n",
      "epoch: 28, loss: 0.8019\n",
      "epoch: 29, loss: 0.6417\n",
      "epoch: 30, loss: 0.3358\n",
      "epoch: 31, loss: 0.5688\n",
      "epoch: 32, loss: 0.3867\n",
      "epoch: 33, loss: 0.5311\n",
      "epoch: 34, loss: 0.6640\n",
      "epoch: 35, loss: 0.9108\n",
      "epoch: 36, loss: 0.5507\n",
      "epoch: 37, loss: 0.6048\n",
      "epoch: 38, loss: 0.6211\n",
      "epoch: 39, loss: 0.5533\n",
      "epoch: 40, loss: 0.6164\n",
      "epoch: 41, loss: 0.5517\n",
      "epoch: 42, loss: 0.5311\n",
      "epoch: 43, loss: 0.6481\n",
      "epoch: 44, loss: 0.6054\n",
      "epoch: 45, loss: 0.4730\n",
      "epoch: 46, loss: 0.8243\n",
      "epoch: 47, loss: 0.4393\n",
      "epoch: 48, loss: 0.7574\n",
      "epoch: 49, loss: 0.4626\n",
      "epoch: 50, loss: 0.5816\n",
      "epoch: 51, loss: 0.6885\n",
      "epoch: 52, loss: 0.3910\n",
      "epoch: 53, loss: 0.6077\n",
      "epoch: 54, loss: 0.6257\n",
      "epoch: 55, loss: 0.4243\n",
      "epoch: 56, loss: 0.6269\n",
      "epoch: 57, loss: 0.7114\n",
      "epoch: 58, loss: 0.7127\n",
      "epoch: 59, loss: 0.7491\n",
      "epoch: 60, loss: 0.5232\n",
      "epoch: 61, loss: 0.3955\n",
      "epoch: 62, loss: 0.5753\n",
      "epoch: 63, loss: 0.4553\n",
      "epoch: 64, loss: 0.5854\n",
      "epoch: 65, loss: 0.4758\n",
      "epoch: 66, loss: 0.6230\n",
      "epoch: 67, loss: 0.6422\n",
      "epoch: 68, loss: 0.6132\n",
      "epoch: 69, loss: 0.8958\n",
      "epoch: 70, loss: 0.7396\n",
      "epoch: 71, loss: 0.7157\n",
      "epoch: 72, loss: 0.4737\n",
      "epoch: 73, loss: 0.6297\n",
      "epoch: 74, loss: 0.9213\n",
      "epoch: 75, loss: 0.6743\n",
      "epoch: 76, loss: 0.6497\n",
      "epoch: 77, loss: 0.9991\n",
      "epoch: 78, loss: 0.5957\n",
      "epoch: 79, loss: 0.7076\n",
      "epoch: 80, loss: 0.7022\n",
      "epoch: 81, loss: 0.4462\n",
      "epoch: 82, loss: 0.4439\n",
      "epoch: 83, loss: 0.9042\n",
      "epoch: 84, loss: 0.5485\n",
      "epoch: 85, loss: 0.6217\n",
      "epoch: 86, loss: 0.7200\n",
      "epoch: 87, loss: 0.6345\n",
      "epoch: 88, loss: 0.8463\n",
      "epoch: 89, loss: 0.6838\n",
      "epoch: 90, loss: 0.5471\n",
      "epoch: 91, loss: 0.6516\n",
      "epoch: 92, loss: 0.5908\n",
      "epoch: 93, loss: 0.5578\n",
      "epoch: 94, loss: 0.4558\n",
      "epoch: 95, loss: 0.4203\n",
      "epoch: 96, loss: 0.6099\n",
      "epoch: 97, loss: 0.6778\n",
      "epoch: 98, loss: 0.6445\n",
      "epoch: 99, loss: 0.7365\n",
      "epoch: 100, loss: 0.6176\n",
      "epoch: 101, loss: 0.6550\n",
      "epoch: 102, loss: 0.4980\n",
      "epoch: 103, loss: 0.4841\n",
      "epoch: 104, loss: 0.5605\n",
      "epoch: 105, loss: 0.3913\n",
      "epoch: 106, loss: 0.7209\n",
      "epoch: 107, loss: 0.5591\n",
      "epoch: 108, loss: 0.5374\n",
      "epoch: 109, loss: 0.8985\n",
      "epoch: 110, loss: 0.6415\n",
      "epoch: 111, loss: 0.4512\n",
      "epoch: 112, loss: 0.5711\n",
      "epoch: 113, loss: 0.5466\n",
      "epoch: 114, loss: 0.5517\n",
      "epoch: 115, loss: 0.8245\n",
      "epoch: 116, loss: 0.5672\n",
      "epoch: 117, loss: 0.7117\n",
      "epoch: 118, loss: 0.6944\n",
      "epoch: 119, loss: 0.6818\n",
      "epoch: 120, loss: 0.5933\n",
      "epoch: 121, loss: 0.5531\n",
      "epoch: 122, loss: 0.5861\n",
      "epoch: 123, loss: 0.8472\n",
      "epoch: 124, loss: 0.5273\n",
      "epoch: 125, loss: 0.5203\n",
      "epoch: 126, loss: 0.9493\n",
      "epoch: 127, loss: 0.6536\n",
      "epoch: 128, loss: 0.5328\n",
      "epoch: 129, loss: 0.6115\n",
      "epoch: 130, loss: 0.4393\n",
      "epoch: 131, loss: 0.4915\n",
      "epoch: 132, loss: 0.5501\n",
      "epoch: 133, loss: 0.8248\n",
      "epoch: 134, loss: 0.5291\n",
      "epoch: 135, loss: 0.7446\n",
      "epoch: 136, loss: 0.7297\n",
      "epoch: 137, loss: 0.5975\n",
      "epoch: 138, loss: 0.7632\n",
      "epoch: 139, loss: 0.4821\n",
      "epoch: 140, loss: 0.7265\n",
      "epoch: 141, loss: 0.6141\n",
      "epoch: 142, loss: 0.6625\n",
      "epoch: 143, loss: 0.6130\n",
      "epoch: 144, loss: 0.5175\n",
      "epoch: 145, loss: 0.6813\n",
      "epoch: 146, loss: 0.6332\n",
      "epoch: 147, loss: 0.8275\n",
      "epoch: 148, loss: 0.8084\n",
      "epoch: 149, loss: 0.6615\n",
      "epoch: 150, loss: 0.7345\n",
      "epoch: 151, loss: 0.6210\n",
      "epoch: 152, loss: 0.7134\n",
      "epoch: 153, loss: 0.8213\n",
      "epoch: 154, loss: 0.7210\n",
      "epoch: 155, loss: 0.7971\n",
      "epoch: 156, loss: 0.8224\n",
      "epoch: 157, loss: 0.8696\n",
      "epoch: 158, loss: 0.6331\n",
      "epoch: 159, loss: 0.6431\n",
      "epoch: 160, loss: 0.9055\n",
      "epoch: 161, loss: 0.4588\n",
      "epoch: 162, loss: 0.8666\n",
      "epoch: 163, loss: 0.5617\n",
      "epoch: 164, loss: 0.7666\n",
      "epoch: 165, loss: 0.7073\n",
      "epoch: 166, loss: 0.5155\n",
      "epoch: 167, loss: 0.5304\n",
      "epoch: 168, loss: 0.8295\n",
      "epoch: 169, loss: 0.8105\n",
      "epoch: 170, loss: 0.6543\n",
      "epoch: 171, loss: 0.4850\n",
      "epoch: 172, loss: 0.6481\n",
      "epoch: 173, loss: 0.7035\n",
      "epoch: 174, loss: 0.5010\n",
      "epoch: 175, loss: 0.4832\n",
      "epoch: 176, loss: 0.7553\n",
      "epoch: 177, loss: 0.6641\n",
      "epoch: 178, loss: 0.5544\n",
      "epoch: 179, loss: 0.5683\n",
      "epoch: 180, loss: 0.5843\n",
      "epoch: 181, loss: 0.8219\n",
      "epoch: 182, loss: 0.6662\n",
      "epoch: 183, loss: 0.4926\n",
      "epoch: 184, loss: 0.4234\n",
      "epoch: 185, loss: 0.6570\n",
      "epoch: 186, loss: 0.5490\n",
      "epoch: 187, loss: 0.5810\n",
      "epoch: 188, loss: 0.7149\n",
      "epoch: 189, loss: 0.4510\n",
      "epoch: 190, loss: 0.6003\n",
      "epoch: 191, loss: 0.5569\n",
      "epoch: 192, loss: 0.7470\n",
      "epoch: 193, loss: 0.4171\n",
      "epoch: 194, loss: 0.3464\n",
      "epoch: 195, loss: 0.4901\n",
      "epoch: 196, loss: 0.6282\n",
      "epoch: 197, loss: 0.5674\n",
      "epoch: 198, loss: 0.7454\n",
      "epoch: 199, loss: 0.8549\n",
      "epoch: 200, loss: 0.5395\n",
      "epoch: 201, loss: 0.7664\n",
      "epoch: 202, loss: 0.4987\n",
      "epoch: 203, loss: 0.6607\n",
      "epoch: 204, loss: 0.5324\n",
      "epoch: 205, loss: 0.6882\n",
      "epoch: 206, loss: 0.7129\n",
      "epoch: 207, loss: 0.8160\n",
      "epoch: 208, loss: 0.5206\n",
      "epoch: 209, loss: 0.7161\n",
      "epoch: 210, loss: 0.7988\n",
      "epoch: 211, loss: 0.5124\n",
      "epoch: 212, loss: 0.7407\n",
      "epoch: 213, loss: 0.5981\n",
      "epoch: 214, loss: 0.7920\n",
      "epoch: 215, loss: 0.6778\n",
      "epoch: 216, loss: 0.7308\n",
      "epoch: 217, loss: 0.7455\n",
      "epoch: 218, loss: 0.7061\n",
      "epoch: 219, loss: 0.5996\n",
      "epoch: 220, loss: 0.6816\n",
      "epoch: 221, loss: 0.5167\n",
      "epoch: 222, loss: 0.5064\n",
      "epoch: 223, loss: 0.6576\n",
      "epoch: 224, loss: 0.4903\n",
      "epoch: 225, loss: 0.6427\n",
      "epoch: 226, loss: 0.6144\n",
      "epoch: 227, loss: 0.6052\n",
      "epoch: 228, loss: 0.5453\n",
      "epoch: 229, loss: 0.7472\n",
      "epoch: 230, loss: 0.4891\n",
      "epoch: 231, loss: 0.7615\n",
      "epoch: 232, loss: 0.6085\n",
      "epoch: 233, loss: 0.6287\n",
      "epoch: 234, loss: 0.2304\n",
      "epoch: 235, loss: 0.5833\n",
      "epoch: 236, loss: 0.6675\n",
      "epoch: 237, loss: 0.6409\n",
      "epoch: 238, loss: 0.6512\n",
      "epoch: 239, loss: 0.6446\n",
      "epoch: 240, loss: 0.5627\n",
      "epoch: 241, loss: 0.4597\n",
      "epoch: 242, loss: 0.5469\n",
      "epoch: 243, loss: 0.6230\n",
      "epoch: 244, loss: 0.8335\n",
      "epoch: 245, loss: 0.7748\n",
      "epoch: 246, loss: 0.6681\n",
      "epoch: 247, loss: 0.8918\n",
      "epoch: 248, loss: 0.5050\n",
      "epoch: 249, loss: 0.5415\n",
      "epoch: 250, loss: 0.7771\n",
      "epoch: 251, loss: 0.5002\n",
      "epoch: 252, loss: 0.4087\n",
      "epoch: 253, loss: 0.6102\n",
      "epoch: 254, loss: 0.3443\n",
      "epoch: 255, loss: 0.5166\n",
      "epoch: 256, loss: 0.5476\n",
      "epoch: 257, loss: 0.7151\n",
      "epoch: 258, loss: 0.6722\n",
      "epoch: 259, loss: 0.7099\n",
      "epoch: 260, loss: 0.6703\n",
      "epoch: 261, loss: 0.7086\n",
      "epoch: 262, loss: 0.5573\n",
      "epoch: 263, loss: 0.5708\n",
      "epoch: 264, loss: 0.6150\n",
      "epoch: 265, loss: 0.6372\n",
      "epoch: 266, loss: 0.4792\n",
      "epoch: 267, loss: 0.4440\n",
      "epoch: 268, loss: 0.7806\n",
      "epoch: 269, loss: 0.5234\n",
      "epoch: 270, loss: 0.5750\n",
      "epoch: 271, loss: 0.6651\n",
      "epoch: 272, loss: 0.4496\n",
      "epoch: 273, loss: 0.5267\n",
      "epoch: 274, loss: 0.5420\n",
      "epoch: 275, loss: 0.6850\n",
      "epoch: 276, loss: 0.7441\n",
      "epoch: 277, loss: 0.6597\n",
      "epoch: 278, loss: 0.6892\n",
      "epoch: 279, loss: 0.9285\n",
      "epoch: 280, loss: 0.6676\n",
      "epoch: 281, loss: 0.4339\n",
      "epoch: 282, loss: 0.4366\n",
      "epoch: 283, loss: 0.6000\n",
      "epoch: 284, loss: 0.7559\n",
      "epoch: 285, loss: 0.5792\n",
      "epoch: 286, loss: 0.6845\n",
      "epoch: 287, loss: 0.7214\n",
      "epoch: 288, loss: 0.6201\n",
      "epoch: 289, loss: 0.7184\n",
      "epoch: 290, loss: 0.5200\n",
      "epoch: 291, loss: 0.5300\n",
      "epoch: 292, loss: 0.3437\n",
      "epoch: 293, loss: 0.6355\n",
      "epoch: 294, loss: 0.4746\n",
      "epoch: 295, loss: 0.3484\n",
      "epoch: 296, loss: 0.5942\n",
      "epoch: 297, loss: 0.6221\n",
      "epoch: 298, loss: 0.5741\n",
      "epoch: 299, loss: 0.6825\n",
      "epoch: 300, loss: 0.6831\n"
     ]
    }
   ],
   "execution_count": 108
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T07:49:36.809515Z",
     "start_time": "2025-04-02T07:49:36.803149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "te_dataset = IrisDataset(iris_datas,\"dev\",target)\n",
    "test(model,te_dataset,config)\n",
    "# te_dataset.target"
   ],
   "id": "ee5ca9cf1ff436f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "test_loss:0.4910810391108195, accuracy: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 109
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
