{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-01T12:23:46.468289Z",
     "start_time": "2025-04-01T12:23:46.465787Z"
    }
   },
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T12:23:46.478104Z",
     "start_time": "2025-04-01T12:23:46.475293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch import optim\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ],
   "id": "dc347e22b048f7f",
   "outputs": [],
   "execution_count": 263
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T12:23:46.498780Z",
     "start_time": "2025-04-01T12:23:46.494587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 自定义数据集\n",
    "class ConvidDataset(Dataset):\n",
    "    def __init__(self,path,mode = \"train\",transform = None):\n",
    "        self.mode = mode\n",
    "        data = pd.read_csv(path)\n",
    "        data = np.array(data[1:])[:,1:].astype(np.float32)\n",
    "        self.transform = transform\n",
    "        features = list(range(93))\n",
    "        if mode == \"test\":\n",
    "            data = data[:,features]\n",
    "            self.data = torch.from_numpy(data).float()\n",
    "        else:\n",
    "            target = data[:,-1]\n",
    "            data = data[:,features]\n",
    "            if mode == 'train':\n",
    "                indices = [i for i in range(len(data)) if i % 10 != 0]\n",
    "            elif mode == 'dev':\n",
    "                indices = [i for i in range(len(data)) if i % 10 == 0]\n",
    "            self.data = torch.from_numpy(data[indices]).float()\n",
    "            self.target = torch.from_numpy(target[indices]).float()\n",
    "        # 归一化\n",
    "        self.data[:, 40:] = \\\n",
    "            (self.data[:, 40:] - self.data[:, 40:].mean(dim=0, keepdim=True)) \\\n",
    "            / self.data[:, 40:].std(dim=0, keepdim=True)\n",
    "        self.dim = self.data.shape[1]\n",
    "        print(f\"读入{mode}数据,数据长度为{len(self.data)},数据维度为{self.dim}\")\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == 'train':\n",
    "            return self.data[index], self.target[index]\n",
    "        else:\n",
    "            return self.data[index]"
   ],
   "id": "4008e2ac5a59104f",
   "outputs": [],
   "execution_count": 264
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T12:23:46.523009Z",
     "start_time": "2025-04-01T12:23:46.500783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "convid_dataset = ConvidDataset('covid.train.csv')\n",
    "convid_dataLoader = DataLoader(convid_dataset,shuffle=True,batch_size=270)"
   ],
   "id": "3ba4f9d9fbbeb3f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读入train数据,数据长度为2429,数据维度为93\n"
     ]
    }
   ],
   "execution_count": 265
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T12:23:46.533763Z",
     "start_time": "2025-04-01T12:23:46.530166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 定义神经网络\n",
    "class CovidNetWork(nn.Module):\n",
    "    def __init__(self,input_dim):\n",
    "        super(CovidNetWork,self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,1),\n",
    "        )\n",
    "        self.criterion = nn.MSELoss(reduction='mean')\n",
    "    def forward(self,x):\n",
    "        return self.net(x).squeeze(1)\n",
    "    def calculate_loss(self,pred, target):\n",
    "        return self.criterion(pred, target)\n"
   ],
   "id": "4278dbcf84998cd5",
   "outputs": [],
   "execution_count": 266
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T12:23:46.544043Z",
     "start_time": "2025-04-01T12:23:46.540602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def dev(dv_set, model, device):\n",
    "    model.eval()                                # set model to evalutation mode\n",
    "    total_loss = 0\n",
    "    for x, y in dv_set:                         # iterate through the dataloader\n",
    "        x, y = x.to(device), y.to(device)       # move data to device (cpu/cuda)\n",
    "        with torch.no_grad():                   # disable gradient calculation\n",
    "            pred = model(x)                     # forward pass (compute output)\n",
    "            mse_loss = model.cal_loss(pred, y)  # compute loss\n",
    "        total_loss += mse_loss.detach().cpu().item() * len(x)  # accumulate loss\n",
    "    total_loss = total_loss / len(dv_set.dataset)              # compute averaged loss\n",
    "\n",
    "    return total_loss"
   ],
   "id": "dec38a0efac8e268",
   "outputs": [],
   "execution_count": 267
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T12:23:46.561843Z",
     "start_time": "2025-04-01T12:23:46.551794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dev_dataset = ConvidDataset('covid.test.csv',\"dev\")\n",
    "dev_dataLoader = DataLoader(dev_dataset,shuffle=True,batch_size=270)"
   ],
   "id": "a119958a0554c123",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读入dev数据,数据长度为90,数据维度为93\n"
     ]
    }
   ],
   "execution_count": 268
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T12:23:46.679269Z",
     "start_time": "2025-04-01T12:23:46.641260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 训练数据\n",
    "model = CovidNetWork(convid_dataset.dim)\n",
    "print(convid_dataset.dim)\n",
    "# 优化器\n",
    "# optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "optimizer = getattr(torch.optim, \"SGD\")(\n",
    "    model.parameters(), lr=0.01, momentum=0.9)\n",
    "epochs = 1500\n",
    "epoch = 0\n",
    "min_mse = 1000\n",
    "while epoch < epochs:\n",
    "        model.train()                           # set model to training mode\n",
    "        for x, y in convid_dataLoader:                     # iterate through the dataloader\n",
    "            optimizer.zero_grad()               # set gradient to zero\n",
    "            x, y = x.to(device), y.to(device)   # move data to device (cpu/cuda)\n",
    "            pred = model(x)                     # forward pass (compute output)\n",
    "            mse_loss = model.calculate_loss(pred, y)  # compute loss\n",
    "            mse_loss.backward()                 # compute gradient (backpropagation)\n",
    "            optimizer.step()                    # update model with optimizer\n",
    "\n",
    "        # After each epoch, test your model on the validation (development) set.\n",
    "        dev_mse = dev(dev_dataLoader, model, device)\n",
    "        if dev_mse < min_mse:\n",
    "            # Save model if your model improved\n",
    "            min_mse = dev_mse\n",
    "            print('Saving model (epoch = {:4d}, loss = {:.4f})'\n",
    "                .format(epoch + 1, min_mse))\n",
    "            early_stop_cnt = 0\n",
    "        else:\n",
    "            early_stop_cnt += 1\n",
    "\n",
    "        epoch += 1\n",
    "        if early_stop_cnt > 200:\n",
    "            break\n",
    "print('Finished training after {} epochs'.format(epoch))\n",
    "# for epoch in range(epochs):\n",
    "#     model.train()\n",
    "#     optimizer.zero_grad()\n",
    "#     pred = model(convid_dataset.data)\n",
    "#     mse_loss = model.calculate_loss(pred, convid_dataset.target)\n",
    "#     mse_loss.backward()\n",
    "#     optimizer.step()\n",
    "#     if epoch % 100 == 1:\n",
    "#         print(f\"epoch:{epoch},mse_loss:{mse_loss}\")"
   ],
   "id": "edf75c118deedb8f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[269], line 22\u001B[0m\n\u001B[0;32m     19\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()                    \u001B[38;5;66;03m# update model with optimizer\u001B[39;00m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m# After each epoch, test your model on the validation (development) set.\u001B[39;00m\n\u001B[1;32m---> 22\u001B[0m dev_mse \u001B[38;5;241m=\u001B[39m dev(dev_dataLoader, model, device)\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dev_mse \u001B[38;5;241m<\u001B[39m min_mse:\n\u001B[0;32m     24\u001B[0m     \u001B[38;5;66;03m# Save model if your model improved\u001B[39;00m\n\u001B[0;32m     25\u001B[0m     min_mse \u001B[38;5;241m=\u001B[39m dev_mse\n",
      "Cell \u001B[1;32mIn[267], line 4\u001B[0m, in \u001B[0;36mdev\u001B[1;34m(dv_set, model, device)\u001B[0m\n\u001B[0;32m      2\u001B[0m model\u001B[38;5;241m.\u001B[39meval()                                \u001B[38;5;66;03m# set model to evalutation mode\u001B[39;00m\n\u001B[0;32m      3\u001B[0m total_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m x, y \u001B[38;5;129;01min\u001B[39;00m dv_set:                         \u001B[38;5;66;03m# iterate through the dataloader\u001B[39;00m\n\u001B[0;32m      5\u001B[0m     x, y \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mto(device), y\u001B[38;5;241m.\u001B[39mto(device)       \u001B[38;5;66;03m# move data to device (cpu/cuda)\u001B[39;00m\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():                   \u001B[38;5;66;03m# disable gradient calculation\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "execution_count": 269
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 保存模型\n",
    "torch.save(model.state_dict(),\"covid.pth\")"
   ],
   "id": "f8c8d35996834c8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 测试数据\n",
    "convid_dataset = ConvidDataset('covid.test.csv',\"test\")\n",
    "convid_dataLoader = DataLoader(convid_dataset,shuffle=True,batch_size=32)\n",
    "model = CovidNetWork(convid_dataset.dim)\n",
    "model.load_state_dict(torch.load(\"covid.pth\"))\n",
    "model.eval()\n",
    "print(convid_dataset.dim)\n",
    "# 优化器\n",
    "model.train()\n",
    "pred = model(convid_dataset.data)\n",
    "\n",
    "print(pred[:10])"
   ],
   "id": "53f29cddc4b851f6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
